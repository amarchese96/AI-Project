{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capsule_Network_Project_2ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzstYvr7w4pW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import numpy as np\n",
        "import itertools as it"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2SRXbbuxY9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "593f9061-c474-4ad7-9bb8-6ac0160e37e0"
      },
      "source": [
        "print(f\"CUDA is available? {torch.cuda.is_available()}\")\n",
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(dev)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available? True\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAZWiLvNyB17",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f432e595-bc0d-4de4-c59a-155683a0358d"
      },
      "source": [
        "drive.mount(\"/content/drive\",True)\n",
        "root_dir = \"/content/drive/My Drive/SB3/\""
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uqJLqOfyYX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def squash(s, dim=-1):\n",
        "\tsquared_norm = torch.sum(s**2, dim=dim, keepdim=True)\n",
        "\treturn squared_norm / (1 + squared_norm) * s / (torch.sqrt(squared_norm) + 1e-8)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE99mgZ3yfho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PrimaryCapsules(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, vector_length, kernel_size, stride, padding):\n",
        "    super().__init__()\n",
        "    self.vector_length = vector_length\n",
        "    self.num_caps_channels = int(out_channels / vector_length)\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = x.view(x.size(0), self.num_caps_channels, x.size(2), x.size(3), self.vector_length)\n",
        "    x = x.view(x.size(0), -1, self.vector_length)\n",
        "    return squash(x)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w81OQ4-tym1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RoutingCapsules(nn.Module):\n",
        "  def __init__(self, in_vector_length, num_in_caps, num_out_caps, out_vector_length, num_routing):\n",
        "    super().__init__()\n",
        "    self.in_vector_length = in_vector_length\n",
        "    self.num_in_caps = num_in_caps\n",
        "    self.num_out_caps = num_out_caps\n",
        "    self.out_vector_length = out_vector_length\n",
        "    self.num_routing = num_routing\n",
        "\n",
        "    self.W = nn.Parameter(torch.randn(1, num_out_caps, num_in_caps, out_vector_length, in_vector_length ) )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    batch_size = x.size(0)\n",
        "    # (batch_size, num_in_caps, in_vector_length) -> (batch_size, 1, num_in_caps, in_vector_length, 1)\n",
        "    x = x.unsqueeze(1).unsqueeze(4)\n",
        "    #\n",
        "    # W @ x =\n",
        "    # (1, num_output_caps, num_in_caps, out_vector_length, in_vector_length) @ (batch_size, 1, num_in_caps, in_vector_length, 1) =\n",
        "    # (batch_size, num_out_caps, num_in_caps, out_vector_length, 1)\n",
        "    u_hat = torch.matmul(self.W, x)\n",
        "    # (batch_size, num_out_caps, num_in_caps, out_vector_length)\n",
        "    u_hat = u_hat.squeeze(-1)\n",
        "    # detach u_hat during routing iterations to prevent gradients from flowing\n",
        "    temp_u_hat = u_hat.detach()\n",
        "\n",
        "    '''\n",
        "    Procedure 1: Routing algorithm\n",
        "    '''\n",
        "    b = torch.zeros(batch_size, self.num_out_caps, self.num_in_caps, 1).to(dev)\n",
        "\n",
        "    for route_iter in range(self.num_routing-1):\n",
        "      # (batch_size, num_out_caps, num_in_caps, 1) -> Softmax along num_out_caps\n",
        "      c = F.softmax(b, dim=1)\n",
        "\n",
        "      # element-wise multiplication\n",
        "      # (batch_size, num_out_caps, num_in_caps, 1) * (batch_size, num_in_caps, num_out_caps, out_vector_length) ->\n",
        "      # (batch_size, num_out_caps, num_in_caps, out_vector_length) sum across num_in_caps ->\n",
        "      # (batch_size, num_out_caps, out_vector_length)\n",
        "      s = (c * temp_u_hat).sum(dim=2)\n",
        "      # apply \"squashing\" non-linearity along dim_caps\n",
        "      v = squash(s)\n",
        "      # dot product agreement between the current output vj and the prediction uj|i\n",
        "      # (batch_size, num_out_caps, num_in_caps, out_vector_length) @ (batch_size, num_out_caps, out_vector_length, 1)\n",
        "      # -> (batch_size, num_out_caps, num_in_caps, 1)\n",
        "      uv = torch.matmul(temp_u_hat, v.unsqueeze(-1))\n",
        "      b += uv\n",
        "\n",
        "    # last iteration is done on the original u_hat, without the routing weights update\n",
        "    c = F.softmax(b, dim=1)\n",
        "    s = (c * u_hat).sum(dim=2)\n",
        "    # apply \"squashing\" non-linearity along dim_caps\n",
        "    v = squash(s)\n",
        "\n",
        "    return v"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k1WJN3cyt9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Reconstruction(nn.Module):\n",
        "    def __init__(self, num_classes, vector_length):\n",
        "      super().__init__()\n",
        "      \n",
        "      self.fc_layer = nn.Sequential(\n",
        "        nn.Linear(num_classes*vector_length, 64),\n",
        "        nn.ReLU()\n",
        "      )\n",
        "\n",
        "      self.reconstruction_layers = nn.Sequential(\n",
        "          nn.ConvTranspose2d(1, 128, kernel_size=5, padding=2, stride=5),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.ConvTranspose2d(128, 64, kernel_size=5, padding=2, stride=3),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ConvTranspose2d(64, 32, kernel_size=5, padding=2, stride=3),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.Conv2d(32, 3, kernel_size=5, padding=4, stride=1),\n",
        "          nn.Sigmoid()\n",
        "    )\n",
        "        \n",
        "    def forward(self, x):\n",
        "      x = self.fc_layer(x)\n",
        "      x = x.view(x.size(0), 1, 8, 8)\n",
        "      x = self.reconstruction_layers(x)\n",
        "      return x"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF2zJ9xjyzjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CapsNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "      super().__init__()\n",
        "      self.conv_layer = nn.Sequential(\n",
        "          nn.Conv2d(3, 64, kernel_size=5, padding=2, stride=4),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.MaxPool2d(kernel_size=5, padding=2, stride=2)\n",
        "      )\n",
        "      self.primary_caps = PrimaryCapsules(in_channels=64, out_channels=128, vector_length=8, kernel_size=5, padding=2, stride=1)\n",
        "      self.digit_caps = nn.Sequential(\n",
        "        RoutingCapsules(in_vector_length=8, num_in_caps=25600, num_out_caps=20, out_vector_length=16, num_routing=3),\n",
        "        RoutingCapsules(in_vector_length=16, num_in_caps=20, num_out_caps=num_classes, out_vector_length=16, num_routing=3)\n",
        "      )\n",
        "      self.reconstruction_layer = Reconstruction(num_classes=num_classes, vector_length=16)\n",
        "    \n",
        "    def forward(self, x):\n",
        "      x = self.conv_layer(x)\n",
        "      x = self.primary_caps(x)\n",
        "      x = self.digit_caps(x)\n",
        "      scores = torch.norm(x,dim=-1)\n",
        "      x = x.view(x.size(0), x.size(1) * x.size(2))\n",
        "      reconstructions = self.reconstruction_layer(x)\n",
        "      return scores, reconstructions"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9A8ExHxy5XA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def margin_loss(pred, labels, num_classes, m_plus=0.9, m_minus=0.1, loss_lambda=0.5):\n",
        "  one_hot_labels = F.one_hot(labels,num_classes = num_classes)\n",
        "  loss = one_hot_labels * F.relu(m_plus - pred)**2 + loss_lambda * (1 - one_hot_labels) * F.relu(pred - m_minus)**2\n",
        "  loss = loss.sum(dim=1)\n",
        "  return loss.mean()"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SybeYa0pzBuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(epochs, dev, num_classes, loaders, lr=0.001, reconstruction_loss_scale=5e-1):\n",
        "    try:\n",
        "        # Create model\n",
        "        model = CapsNet(num_classes=num_classes)\n",
        "        model = model.to(dev)\n",
        "        # Optimizer\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "        # Initialize history\n",
        "        history_loss = {\"train\": [], \"val\": [], \"test\": []}\n",
        "        history_accuracy = {\"train\": [], \"val\": [], \"test\": []}\n",
        "        # Initialize best validation accuracy and test accuracy at best validation accuracy\n",
        "        best_val_accuracy = 0.0\n",
        "        test_accuracy_at_best_val = 0.0\n",
        "        best_val_per_class_accuracy = torch.zeros(num_classes).to(dev)\n",
        "        test_per_class_accuracy_at_best_val = torch.zeros(num_classes).to(dev)\n",
        "        batch_confusion_matrix = torch.zeros(num_classes, num_classes , dtype=torch.int64).to(dev)\n",
        "        # Process each epoch\n",
        "        for epoch in range(epochs):\n",
        "            # Initialize epoch variables\n",
        "            sum_loss = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "            sum_accuracy = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "            confusion_matrix = {\"train\": torch.zeros(num_classes, num_classes , dtype=torch.int64).to(dev), \"val\": torch.zeros(num_classes, num_classes , dtype=torch.int64).to(dev), \"test\": torch.zeros(num_classes, num_classes , dtype=torch.int64).to(dev)}\n",
        "            # Process each split\n",
        "            for split in [\"train\", \"val\", \"test\"]:\n",
        "                if split == \"train\":\n",
        "                  model.train()\n",
        "                else:\n",
        "                  model.eval()\n",
        "                # Process each batch\n",
        "                for (input, labels) in loaders[split]:\n",
        "                    # Move to CUDA\n",
        "                    input = input.to(dev)\n",
        "                    labels = labels.to(dev)\n",
        "                    # Reset gradients\n",
        "                    optimizer.zero_grad()\n",
        "                    # Compute output\n",
        "                    pred, reconstructions = model(input)\n",
        "                    #score_loss = F.cross_entropy(pred, labels, weight=weights)\n",
        "                    score_loss = margin_loss(pred, labels, num_classes, m_plus=0.9, m_minus=0.1, loss_lambda=0.5)\n",
        "                    reconstruction_loss = F.mse_loss(input, reconstructions) * reconstruction_loss_scale\n",
        "                    loss = score_loss + reconstruction_loss\n",
        "                    # Update loss\n",
        "                    sum_loss[split] += loss.item()\n",
        "                    # Check parameter update\n",
        "                    if split == \"train\":\n",
        "                        # Compute gradients\n",
        "                        loss.backward()\n",
        "                        # Optimize\n",
        "                        optimizer.step()\n",
        "                    # Compute accuracy\n",
        "                    _,pred_labels = pred.max(1)\n",
        "                    batch_accuracy = (pred_labels == labels).sum().item()/input.size(0)\n",
        "                    # Update accuracy\n",
        "                    sum_accuracy[split] += batch_accuracy\n",
        "                    #Update Confusion Matrix\n",
        "                    for label, pred in zip(labels.view(-1), pred_labels.view(-1)):\n",
        "                      confusion_matrix[split][label, pred] += 1\n",
        "            # Compute epoch loss/accuracy\n",
        "            epoch_loss = {split: sum_loss[split]/len(loaders[split]) for split in [\"train\", \"val\", \"test\"]}\n",
        "            epoch_accuracy = {split: sum_accuracy[split]/len(loaders[split]) for split in [\"train\", \"val\", \"test\"]}\n",
        "            # Update history\n",
        "            for split in [\"train\", \"val\", \"test\"]:\n",
        "                history_loss[split].append(epoch_loss[split])\n",
        "                history_accuracy[split].append(epoch_accuracy[split])\n",
        "            # Print info\n",
        "            print(f\"Epoch {epoch+1}:\",\n",
        "                  f\"TrL={epoch_loss['train']:.4f},\",\n",
        "                  f\"TrA={epoch_accuracy['train']:.4f},\",\n",
        "                  f\"VL={epoch_loss['val']:.4f},\",\n",
        "                  f\"VA={epoch_accuracy['val']:.4f},\",\n",
        "                  f\"TeL={epoch_loss['test']:.4f},\",\n",
        "                  f\"TeA={epoch_accuracy['test']:.4f},\\n\"\n",
        "                )\n",
        "            # Check if we obtained the best validation accuracy\n",
        "            if best_val_accuracy == 0.0 or epoch_accuracy[\"val\"] > best_val_accuracy:\n",
        "              # Update best validation accuracy and test accuracy at best validation\n",
        "              best_val_accuracy = epoch_accuracy[\"val\"]\n",
        "              test_accuracy_at_best_val = epoch_accuracy[\"test\"]\n",
        "              best_val_per_class_accuracy = confusion_matrix['val'].diag()/confusion_matrix['val'].sum(1).double()\n",
        "              test_per_class_accuracy_at_best_val = confusion_matrix['test'].diag()/confusion_matrix['test'].sum(1).double()\n",
        "            #Print per-class accuracy\n",
        "            print(f\"Training per-class accuracy: {(confusion_matrix['train'].diag()/confusion_matrix['train'].sum(1).double()).tolist()}\")\n",
        "            print(f\"Validation per-class accuracy: {(confusion_matrix['val'].diag()/confusion_matrix['val'].sum(1).double()).tolist()}\")\n",
        "            print(f\"Test per-class accuracy: {(confusion_matrix['test'].diag()/confusion_matrix['test'].sum(1).double()).tolist()} \\n\")\n",
        "            print(f\"----------------------------------\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Interrupted\")\n",
        "    finally:\n",
        "        # Plot loss\n",
        "        plt.title(\"Loss\")\n",
        "        for split in [\"train\", \"val\", \"test\"]:\n",
        "            plt.plot(history_loss[split], label=split)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        # Plot accuracy\n",
        "        plt.title(\"Accuracy\")\n",
        "        for split in [\"train\", \"val\", \"test\"]:\n",
        "            plt.plot(history_accuracy[split], label=split)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        return(best_val_accuracy, test_accuracy_at_best_val, best_val_per_class_accuracy, test_per_class_accuracy_at_best_val)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROdSFZPL0Xbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WrapperDataset(Dataset):\n",
        "  def __init__(self, dataset, map_fn):\n",
        "    self.dataset = dataset\n",
        "    self.map = map_fn\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    return (self.map(self.dataset[index][0]), self.dataset[index][1])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amuT30br0Sln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform = T.Compose([\n",
        "    T.Resize(320),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "test_transform = T.Compose([\n",
        "    T.Resize(320),\n",
        "    T.ToTensor()\n",
        "])"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBvyhrzS0ILk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca3c747c-0e21-416d-9f42-5e96ed861e90"
      },
      "source": [
        "train_dataset = ImageFolder(os.path.join(root_dir, \"train\"))\n",
        "test_dataset = ImageFolder(os.path.join(root_dir, \"test\"), transform=test_transform)\n",
        "num_classes = len(train_dataset.classes)\n",
        "print(num_classes)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC41vuVn1FLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0f6a9422-a7b0-4d5a-aa7d-d87e0bdfbe59"
      },
      "source": [
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1109\n",
            "471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogzA6sor3p9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "08787a43-17c4-4661-90b4-e6f98dff62a8"
      },
      "source": [
        "val_frac = 0.2\n",
        "class_counts = [train_dataset.targets.count(i) for i in range(num_classes)]\n",
        "print(f\"Class counts {class_counts}\")\n",
        "train_counts = [x-int(x*val_frac) for x in class_counts]\n",
        "print(f\"Train counts {train_counts}\")\n",
        "val_counts = [int(x*val_frac) for x in class_counts]\n",
        "print(f\"Val counts {val_counts}\")\n",
        "test_counts = [test_dataset.targets.count(i) for i in range(num_classes)]\n",
        "print(f\"Test counts {test_counts}\")"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class counts [500, 28, 38, 116, 17, 19, 339, 52]\n",
            "Train counts [400, 23, 31, 93, 14, 16, 272, 42]\n",
            "Val counts [100, 5, 7, 23, 3, 3, 67, 10]\n",
            "Test counts [214, 12, 16, 49, 6, 7, 145, 22]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKBblhFm3L_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_dataset, test_dataset, class_idx, train_transform, test_transform, val_frac, num_classes, index):\n",
        "  if index < int(1 / val_frac) - 1:\n",
        "    val_idx = [x[index*int(len(x)*val_frac):index*int(len(x)*val_frac) + int(len(x)*val_frac)] for x in class_idx]\n",
        "    train_idx = [x[:index*int(len(x)*val_frac)] + x[index*int(len(x)*val_frac) + int(len(x)*val_frac):] for x in class_idx]\n",
        "  else:\n",
        "    val_idx = [x[index*int(len(x)*val_frac):] for x in class_idx]\n",
        "    train_idx = [x[:index*int(len(x)*val_frac)] for x in class_idx]\n",
        "  \n",
        "  train_idx = list(it.chain.from_iterable(train_idx))\n",
        "  val_idx = list(it.chain.from_iterable(val_idx))\n",
        "  \n",
        "  val_dataset = Subset(train_dataset,val_idx)\n",
        "  train_dataset = Subset(train_dataset, train_idx)\n",
        "\n",
        "  train_dataset = WrapperDataset(train_dataset,train_transform)\n",
        "  val_dataset = WrapperDataset(val_dataset,test_transform)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=4, num_workers=4, shuffle=True)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=4, num_workers=4, shuffle=False)\n",
        "  test_loader = DataLoader(test_dataset,   batch_size=4, num_workers=4, shuffle=False)\n",
        "  loaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"val\" : val_loader,\n",
        "    \"test\": test_loader\n",
        "  }\n",
        "\n",
        "  return train_model(30, dev, num_classes, loaders, lr=0.001, reconstruction_loss_scale=5e-1)\n"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vR1U6QsZarK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train = len(train_dataset)\n",
        "idx = list(range(num_train))\n",
        "idx_iter = iter(idx)\n",
        "class_idx = [list(it.islice(idx_iter, x)) for x in class_counts]\n",
        "class_idx = [random.sample(x,len(x)) for x in class_idx]"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaN_p3_T66rD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ae94ab2-c0f5-486b-fe5c-50737a4257a6"
      },
      "source": [
        "k = int(1 / val_frac)\n",
        "sum_best_val_accuracy = 0.0\n",
        "sum_test_accuracy_at_best_val = 0.0\n",
        "sum_best_val_per_class_accuracy = torch.zeros(num_classes).to(dev)\n",
        "sum_test_per_class_accuracy_at_best_val = torch.zeros(num_classes).to(dev)\n",
        "for i in range(k):\n",
        "  best_val_accuracy, test_accuracy_at_best_val, best_val_per_class_accuracy, test_per_class_accuracy_at_best_val = train(train_dataset, test_dataset, class_idx, train_transform, test_transform, val_frac, num_classes, i)\n",
        "  sum_best_val_accuracy += best_val_accuracy\n",
        "  sum_test_accuracy_at_best_val += test_accuracy_at_best_val\n",
        "  sum_best_val_per_class_accuracy += best_val_per_class_accuracy\n",
        "  sum_test_per_class_accuracy_at_best_val += test_per_class_accuracy_at_best_val\n",
        "  print(\"--------------------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: TrL=0.8552, TrA=0.3296, VL=0.4519, VA=0.3818, TeL=0.4370, TeA=0.4492,\n",
            "\n",
            "Training per-class accuracy: [0.405, 0.0, 0.03225806451612903, 0.08602150537634409, 0.0, 0.0625, 0.4485294117647059, 0.0]\n",
            "Validation per-class accuracy: [0.35, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7313432835820896, 0.0]\n",
            "Test per-class accuracy: [0.49065420560747663, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7379310344827587, 0.0] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 2: TrL=0.4340, TrA=0.4096, VL=0.4407, VA=0.3318, TeL=0.4324, TeA=0.3538,\n",
            "\n",
            "Training per-class accuracy: [0.665, 0.13043478260869565, 0.0, 0.06451612903225806, 0.0, 0.0, 0.3272058823529412, 0.023809523809523808]\n",
            "Validation per-class accuracy: [0.06, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
            "Test per-class accuracy: [0.09813084112149532, 0.0, 0.0, 0.02040816326530612, 0.16666666666666666, 0.0, 0.993103448275862, 0.0] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 3: TrL=0.4126, TrA=0.4290, VL=0.4352, VA=0.5136, TeL=0.4133, TeA=0.5127,\n",
            "\n",
            "Training per-class accuracy: [0.5975, 0.17391304347826086, 0.0, 0.043010752688172046, 0.14285714285714285, 0.0, 0.4889705882352941, 0.0]\n",
            "Validation per-class accuracy: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19402985074626866, 0.0]\n",
            "Test per-class accuracy: [0.9906542056074766, 0.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.2, 0.0] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 4: TrL=0.3358, TrA=0.5120, VL=0.3427, VA=0.4955, TeL=0.3322, TeA=0.5572,\n",
            "\n",
            "Training per-class accuracy: [0.7775, 0.391304347826087, 0.0, 0.0967741935483871, 0.35714285714285715, 0.0625, 0.4411764705882353, 0.023809523809523808]\n",
            "Validation per-class accuracy: [0.74, 0.2, 0.0, 0.043478260869565216, 0.0, 0.0, 0.4925373134328358, 0.0]\n",
            "Test per-class accuracy: [0.8411214953271028, 0.3333333333333333, 0.0, 0.02040816326530612, 0.3333333333333333, 0.0, 0.5241379310344828, 0.0] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 5: TrL=0.3179, TrA=0.5392, VL=0.3560, VA=0.5045, TeL=0.3346, TeA=0.5169,\n",
            "\n",
            "Training per-class accuracy: [0.8075, 0.391304347826087, 0.0, 0.24731182795698925, 0.2857142857142857, 0.0625, 0.4227941176470588, 0.14285714285714285]\n",
            "Validation per-class accuracy: [0.5, 0.2, 0.0, 0.30434782608695654, 0.0, 0.0, 0.7910447761194029, 0.0]\n",
            "Test per-class accuracy: [0.5654205607476636, 0.25, 0.0, 0.1836734693877551, 0.16666666666666666, 0.0, 0.7241379310344828, 0.22727272727272727] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 6: TrL=0.2788, TrA=0.6072, VL=0.3433, VA=0.4864, TeL=0.3357, TeA=0.4852,\n",
            "\n",
            "Training per-class accuracy: [0.8475, 0.6956521739130435, 0.0, 0.3010752688172043, 0.5, 0.3125, 0.5220588235294118, 0.09523809523809523]\n",
            "Validation per-class accuracy: [0.99, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07462686567164178, 0.2]\n",
            "Test per-class accuracy: [0.9953271028037384, 0.16666666666666666, 0.0, 0.02040816326530612, 0.3333333333333333, 0.14285714285714285, 0.05517241379310345, 0.09090909090909091] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 7: TrL=0.2533, TrA=0.6398, VL=0.3147, VA=0.5364, TeL=0.2913, TeA=0.5869,\n",
            "\n",
            "Training per-class accuracy: [0.81, 0.6086956521739131, 0.06451612903225806, 0.3655913978494624, 0.7142857142857143, 0.375, 0.6139705882352942, 0.30952380952380953]\n",
            "Validation per-class accuracy: [0.62, 0.0, 0.14285714285714285, 0.08695652173913043, 0.0, 0.3333333333333333, 0.7611940298507462, 0.1]\n",
            "Test per-class accuracy: [0.6682242990654206, 0.4166666666666667, 0.0, 0.08163265306122448, 0.3333333333333333, 0.42857142857142855, 0.7724137931034483, 0.36363636363636365] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 8: TrL=0.2275, TrA=0.6824, VL=0.2806, VA=0.6045, TeL=0.2608, TeA=0.6370,\n",
            "\n",
            "Training per-class accuracy: [0.8625, 0.6521739130434783, 0.12903225806451613, 0.3978494623655914, 0.7142857142857143, 0.6875, 0.6286764705882353, 0.35714285714285715]\n",
            "Validation per-class accuracy: [0.74, 0.4, 0.14285714285714285, 0.30434782608695654, 0.0, 0.3333333333333333, 0.6567164179104478, 0.3]\n",
            "Test per-class accuracy: [0.7663551401869159, 0.75, 0.0, 0.3469387755102041, 0.3333333333333333, 0.5714285714285714, 0.6275862068965518, 0.5909090909090909] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 9: TrL=0.1835, TrA=0.7825, VL=0.2608, VA=0.6182, TeL=0.2471, TeA=0.6716,\n",
            "\n",
            "Training per-class accuracy: [0.9025, 0.8695652173913043, 0.41935483870967744, 0.5268817204301075, 0.8571428571428571, 0.875, 0.7573529411764706, 0.5238095238095238]\n",
            "Validation per-class accuracy: [0.78, 0.2, 0.2857142857142857, 0.30434782608695654, 0.0, 0.3333333333333333, 0.7014925373134329, 0.0]\n",
            "Test per-class accuracy: [0.8411214953271028, 0.25, 0.25, 0.2653061224489796, 0.3333333333333333, 0.7142857142857143, 0.7034482758620689, 0.36363636363636365] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 10: TrL=0.1577, TrA=0.8191, VL=0.2655, VA=0.6818, TeL=0.2586, TeA=0.6716,\n",
            "\n",
            "Training per-class accuracy: [0.9025, 0.8695652173913043, 0.5483870967741935, 0.6451612903225806, 1.0, 0.9375, 0.7941176470588235, 0.6428571428571429]\n",
            "Validation per-class accuracy: [0.89, 0.2, 0.42857142857142855, 0.5217391304347826, 0.3333333333333333, 0.3333333333333333, 0.6119402985074627, 0.1]\n",
            "Test per-class accuracy: [0.883177570093458, 0.25, 0.25, 0.32653061224489793, 0.3333333333333333, 0.5714285714285714, 0.6206896551724138, 0.4090909090909091] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 11: TrL=0.1329, TrA=0.8569, VL=0.2709, VA=0.6227, TeL=0.2777, TeA=0.6038,\n",
            "\n",
            "Training per-class accuracy: [0.9125, 0.8695652173913043, 0.8064516129032258, 0.7311827956989247, 0.9285714285714286, 1.0, 0.8272058823529411, 0.7619047619047619]\n",
            "Validation per-class accuracy: [0.98, 0.2, 0.14285714285714285, 0.30434782608695654, 0.3333333333333333, 0.0, 0.40298507462686567, 0.1]\n",
            "Test per-class accuracy: [0.985981308411215, 0.25, 0.1875, 0.20408163265306123, 0.3333333333333333, 0.42857142857142855, 0.32413793103448274, 0.2727272727272727] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 12: TrL=0.1167, TrA=0.8778, VL=0.2660, VA=0.6545, TeL=0.2567, TeA=0.6229,\n",
            "\n",
            "Training per-class accuracy: [0.9375, 0.9130434782608695, 0.6774193548387096, 0.7311827956989247, 1.0, 0.875, 0.8602941176470589, 0.8333333333333334]\n",
            "Validation per-class accuracy: [0.93, 0.4, 0.42857142857142855, 0.34782608695652173, 0.3333333333333333, 0.3333333333333333, 0.5074626865671642, 0.1]\n",
            "Test per-class accuracy: [0.9205607476635514, 0.5, 0.1875, 0.24489795918367346, 0.3333333333333333, 0.5714285714285714, 0.42758620689655175, 0.36363636363636365] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 13: TrL=0.0750, TrA=0.9372, VL=0.2559, VA=0.6773, TeL=0.2304, TeA=0.7090,\n",
            "\n",
            "Training per-class accuracy: [0.96, 0.9565217391304348, 0.9354838709677419, 0.8817204301075269, 0.8571428571428571, 1.0, 0.9191176470588235, 0.9523809523809523]\n",
            "Validation per-class accuracy: [0.7, 0.4, 0.5714285714285714, 0.6086956521739131, 0.3333333333333333, 0.3333333333333333, 0.8059701492537313, 0.2]\n",
            "Test per-class accuracy: [0.7383177570093458, 0.4166666666666667, 0.25, 0.5918367346938775, 0.3333333333333333, 0.7142857142857143, 0.8206896551724138, 0.5454545454545454] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 14: TrL=0.0606, TrA=0.9664, VL=0.2325, VA=0.7182, TeL=0.2243, TeA=0.7090,\n",
            "\n",
            "Training per-class accuracy: [0.98, 0.9130434782608695, 0.9032258064516129, 0.9139784946236559, 1.0, 1.0, 0.9669117647058824, 1.0]\n",
            "Validation per-class accuracy: [0.89, 0.4, 0.5714285714285714, 0.4782608695652174, 0.3333333333333333, 0.3333333333333333, 0.6716417910447762, 0.3]\n",
            "Test per-class accuracy: [0.8878504672897196, 0.5, 0.1875, 0.42857142857142855, 0.3333333333333333, 0.8571428571428571, 0.6344827586206897, 0.6363636363636364] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 15: TrL=0.0438, TrA=0.9776, VL=0.2176, VA=0.7545, TeL=0.2139, TeA=0.7458,\n",
            "\n",
            "Training per-class accuracy: [0.9875, 0.9565217391304348, 0.9354838709677419, 0.956989247311828, 1.0, 1.0, 0.9742647058823529, 0.9761904761904762]\n",
            "Validation per-class accuracy: [0.81, 0.4, 0.5714285714285714, 0.8695652173913043, 0.3333333333333333, 0.3333333333333333, 0.746268656716418, 0.5]\n",
            "Test per-class accuracy: [0.8177570093457944, 0.5833333333333334, 0.25, 0.7142857142857143, 0.3333333333333333, 1.0, 0.7172413793103448, 0.7727272727272727] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 16: TrL=0.0325, TrA=0.9843, VL=0.2165, VA=0.7318, TeL=0.2121, TeA=0.7479,\n",
            "\n",
            "Training per-class accuracy: [0.9925, 0.9565217391304348, 0.967741935483871, 0.978494623655914, 1.0, 1.0, 0.9742647058823529, 1.0]\n",
            "Validation per-class accuracy: [0.69, 0.8, 0.5714285714285714, 0.7391304347826086, 0.3333333333333333, 0.3333333333333333, 0.8656716417910447, 0.5]\n",
            "Test per-class accuracy: [0.7242990654205608, 0.6666666666666666, 0.375, 0.7346938775510204, 0.3333333333333333, 1.0, 0.8344827586206897, 0.7727272727272727] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 17: TrL=0.0240, TrA=0.9966, VL=0.2208, VA=0.7500, TeL=0.2108, TeA=0.7281,\n",
            "\n",
            "Training per-class accuracy: [1.0, 1.0, 1.0, 0.978494623655914, 1.0, 1.0, 0.9963235294117647, 1.0]\n",
            "Validation per-class accuracy: [0.9, 0.6, 0.42857142857142855, 0.6956521739130435, 0.3333333333333333, 0.3333333333333333, 0.6865671641791045, 0.3]\n",
            "Test per-class accuracy: [0.883177570093458, 0.5, 0.25, 0.6122448979591837, 0.3333333333333333, 0.7142857142857143, 0.6344827586206897, 0.6818181818181818] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 18: TrL=0.0205, TrA=0.9944, VL=0.2212, VA=0.7545, TeL=0.2185, TeA=0.7648,\n",
            "\n",
            "Training per-class accuracy: [0.9975, 0.9565217391304348, 1.0, 0.978494623655914, 1.0, 1.0, 0.9963235294117647, 1.0]\n",
            "Validation per-class accuracy: [0.76, 0.8, 0.7142857142857143, 0.6956521739130435, 0.3333333333333333, 0.3333333333333333, 0.8656716417910447, 0.4]\n",
            "Test per-class accuracy: [0.7523364485981309, 0.5833333333333334, 0.5625, 0.673469387755102, 0.3333333333333333, 1.0, 0.8551724137931035, 0.7727272727272727] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 19: TrL=0.0214, TrA=0.9922, VL=0.2371, VA=0.7136, TeL=0.2214, TeA=0.7196,\n",
            "\n",
            "Training per-class accuracy: [0.9975, 1.0, 0.967741935483871, 0.978494623655914, 1.0, 1.0, 0.9889705882352942, 1.0]\n",
            "Validation per-class accuracy: [0.9, 0.8, 0.5714285714285714, 0.4782608695652174, 0.3333333333333333, 0.3333333333333333, 0.6119402985074627, 0.3]\n",
            "Test per-class accuracy: [0.9345794392523364, 0.8333333333333334, 0.25, 0.42857142857142855, 0.3333333333333333, 0.5714285714285714, 0.593103448275862, 0.5454545454545454] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 20: TrL=0.0173, TrA=0.9978, VL=0.2203, VA=0.7500, TeL=0.2009, TeA=0.7627,\n",
            "\n",
            "Training per-class accuracy: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9926470588235294, 1.0]\n",
            "Validation per-class accuracy: [0.86, 0.8, 0.5714285714285714, 0.6521739130434783, 0.3333333333333333, 0.3333333333333333, 0.7014925373134329, 0.5]\n",
            "Test per-class accuracy: [0.8644859813084113, 0.8333333333333334, 0.25, 0.6530612244897959, 0.3333333333333333, 0.8571428571428571, 0.7103448275862069, 0.7727272727272727] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 21: TrL=0.0167, TrA=0.9966, VL=0.2202, VA=0.7318, TeL=0.2056, TeA=0.7669,\n",
            "\n",
            "Training per-class accuracy: [1.0, 1.0, 0.967741935483871, 0.989247311827957, 1.0, 1.0, 0.9963235294117647, 1.0]\n",
            "Validation per-class accuracy: [0.71, 1.0, 0.7142857142857143, 0.782608695652174, 0.3333333333333333, 0.3333333333333333, 0.7910447761194029, 0.5]\n",
            "Test per-class accuracy: [0.7757009345794392, 0.8333333333333334, 0.4375, 0.7142857142857143, 0.5, 0.8571428571428571, 0.8137931034482758, 0.7272727272727273] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 22: TrL=0.0158, TrA=0.9989, VL=0.2110, VA=0.7773, TeL=0.1963, TeA=0.7733,\n",
            "\n",
            "Training per-class accuracy: [1.0, 1.0, 1.0, 0.989247311827957, 1.0, 1.0, 1.0, 1.0]\n",
            "Validation per-class accuracy: [0.82, 0.8, 0.7142857142857143, 0.7391304347826086, 0.3333333333333333, 0.3333333333333333, 0.7910447761194029, 0.6]\n",
            "Test per-class accuracy: [0.8644859813084113, 0.6666666666666666, 0.5625, 0.6938775510204082, 0.3333333333333333, 0.7142857142857143, 0.7172413793103448, 0.7727272727272727] \n",
            "\n",
            "----------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ricYeQkt8K3c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "e6ab391a-71e1-45e5-e264-5f2955b72dc1"
      },
      "source": [
        "# Print best validation accuracy and test accuracy at best validation \n",
        "print(f\"Mean best validation accuracy: {sum_best_val_accuracy / k}\")\n",
        "print(f\"Mean test accuracy at best validation: {sum_test_accuracy_at_best_val / k}\")\n",
        "print(f\"Mean best per-class validation accuracy: {(sum_best_val_per_class_accuracy / k).tolist()}\")\n",
        "print(f\"Mean test per-class accuracy at best validation: {(sum_test_per_class_accuracy_at_best_val / k).tolist()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean best validation accuracy: 0.7636363636363637\n",
            "Mean test accuracy at best validation: 0.7561793785310734\n",
            "Mean best per-class validation accuracy: [0.8224999904632568, 0.949999988079071, 0.5357142686843872, 0.695652186870575, 0.5833333134651184, 0.8333333730697632, 0.7611939907073975, 0.5249999761581421]\n",
            "Mean test per-class accuracy at best validation: [0.8107476830482483, 0.8541666269302368, 0.3125, 0.7040815949440002, 0.4583333432674408, 0.8214285969734192, 0.7534483075141907, 0.6818181872367859]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
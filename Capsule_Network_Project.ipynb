{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capsule_Network_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nZvdAUbRrX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import numpy as np\n",
        "import itertools as it"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZatW3jZwR-38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6551b3be-159d-42b3-80db-94af593c6d4a"
      },
      "source": [
        "print(f\"CUDA is available? {torch.cuda.is_available()}\")\n",
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(dev)"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available? True\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTYBpe-9SA6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b2d27cd-3a7a-4083-cc94-10a3ea158062"
      },
      "source": [
        "drive.mount(\"/content/drive\",True)\n",
        "root_dir = \"/content/drive/My Drive/SB3/\""
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rldL-WKSBuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform = T.Compose([\n",
        "    T.Resize(320),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "test_transform = T.Compose([\n",
        "    T.Resize(320),\n",
        "    T.ToTensor()\n",
        "])"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTAga3c5SGos",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ea35611-8754-4838-c821-9c6a8e7933ea"
      },
      "source": [
        "train_dataset = ImageFolder(os.path.join(root_dir, \"train\"), transform=train_transform)\n",
        "test_dataset = ImageFolder(os.path.join(root_dir, \"test\"), transform=test_transform)\n",
        "num_classes = len(train_dataset.classes)\n",
        "print(num_classes)"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA59yhfx3rj5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "de0fb7b3-7167-460b-95a4-80743f58de06"
      },
      "source": [
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1109\n",
            "471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIXTmrPp0C7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "cd6f235c-c241-4ccc-b712-edd846bb40fe"
      },
      "source": [
        "x = train_dataset[0][0]\n",
        "print(x.max())\n",
        "print(x.min())"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.9961)\n",
            "tensor(0.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqDBfdoG0DXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5bc3e885-971f-4b3a-f987-89e7cadd8b5d"
      },
      "source": [
        "class_counts = [train_dataset.targets.count(i) for i in range(num_classes)]\n",
        "print(class_counts)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[500, 28, 38, 116, 17, 19, 339, 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-wJ1KbeYthE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train = len(train_dataset)\n",
        "idx = list(range(num_train))\n",
        "val_frac = 0.2\n",
        "idx_iter = iter(idx)\n",
        "class_idx = [list(it.islice(idx_iter, x)) for x in class_counts]\n",
        "class_idx = [random.sample(x,len(x)) for x in class_idx]\n",
        "train_idx = [x[:-int(len(x)*val_frac)] for x in class_idx]\n",
        "train_idx = list(it.chain.from_iterable(train_idx))\n",
        "val_idx = [x[-int(len(x)*val_frac):] for x in class_idx]\n",
        "val_idx = list(it.chain.from_iterable(val_idx))\n",
        "val_dataset = Subset(train_dataset,val_idx)\n",
        "train_dataset = Subset(train_dataset, train_idx)"
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt7N8rXH-PYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0547a436-b934-4637-9d84-74b82ee06510"
      },
      "source": [
        "print(len(train_dataset))\n",
        "print(len(val_dataset))"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "891\n",
            "218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cenTm_mFN_0V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "544b1558-3c8f-4eaf-f27f-6fe64739bbff"
      },
      "source": [
        "train_counts = [x-int(x*val_frac) for x in class_counts]\n",
        "max_count = max(train_counts)\n",
        "#weights = len(train_dataset) / torch.Tensor(train_counts)\n",
        "#weights = max_count / torch.Tensor(train_counts)\n",
        "weights = 1 / torch.Tensor(train_counts)\n",
        "weights = weights.to(dev)\n",
        "print(weights)"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0025, 0.0435, 0.0323, 0.0108, 0.0714, 0.0625, 0.0037, 0.0238],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmmX5OCPqoJs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1cdbc304-2e8f-4d45-c639-0b39121af030"
      },
      "source": [
        "val_counts = [int(x*val_frac) for x in class_counts]\n",
        "print(val_counts)"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[100, 5, 7, 23, 3, 3, 67, 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9SIeKL_SMm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=4, num_workers=4, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, num_workers=4, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset,   batch_size=4, num_workers=4, shuffle=False)\n",
        "loaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"val\" : val_loader,\n",
        "    \"test\": test_loader\n",
        "}"
      ],
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgR4FQ2tU2jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def squash(s, dim=-1):\n",
        "\t'''\n",
        "\t\"Squashing\" non-linearity that shrunks short vectors to almost zero length and long vectors to a length slightly below 1\n",
        "\tEq. (1): v_j = ||s_j||^2 / (1 + ||s_j||^2) * s_j / ||s_j||\n",
        "\t\n",
        "\tArgs:\n",
        "\t\ts: \tVector before activation\n",
        "\t\tdim:\tDimension along which to calculate the norm\n",
        "\t\n",
        "\tReturns:\n",
        "\t\tSquashed vector\n",
        "\t'''\n",
        "\tsquared_norm = torch.sum(s**2, dim=dim, keepdim=True)\n",
        "\treturn squared_norm / (1 + squared_norm) * s / (torch.sqrt(squared_norm) + 1e-8)"
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q1JXyMoSQKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PrimaryCapsules(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, vector_length, kernel_size, stride, padding):\n",
        "    \"\"\"\n",
        "    Initialize the layer.\n",
        "    Args:\n",
        "      in_channels: \tNumber of input channels.\n",
        "      out_channels: \tNumber of output channels.\n",
        "      vector_length:\t\tDimensionality, i.e. length, of the output capsule vector.\n",
        "\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.vector_length = vector_length\n",
        "    self.num_caps_channels = int(out_channels / vector_length)\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = x.view(x.size(0), self.num_caps_channels, x.size(2), x.size(3), self.vector_length)\n",
        "    x = x.view(x.size(0), -1, self.vector_length)\n",
        "    return squash(x)\n"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6uiDtWVSmUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RoutingCapsules(nn.Module):\n",
        "  def __init__(self, in_vector_length, num_in_caps, num_out_caps, out_vector_length, num_routing):\n",
        "    '''\n",
        "\t\tInitialize the layer.\n",
        "\t\tArgs:\n",
        "\t\t\tin_vector_length: \t\tDimensionality (i.e. length) of each capsule vector.\n",
        "\t\t\tnum_in_caps: \t\tNumber of input capsules if digits layer.\n",
        "\t\t\tnum_out_caps: \t\tNumber of capsules in the capsule layer\n",
        "\t\t\tout_vector_length: \t\tDimensionality, i.e. length, of the output capsule vector.\n",
        "\t\t\tnum_routing:\tNumber of iterations during routing algorithm\t\t\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.in_vector_length = in_vector_length\n",
        "    self.num_in_caps = num_in_caps\n",
        "    self.num_out_caps = num_out_caps\n",
        "    self.out_vector_length = out_vector_length\n",
        "    self.num_routing = num_routing\n",
        "\n",
        "    self.W = nn.Parameter(torch.randn(1, num_out_caps, num_in_caps, out_vector_length, in_vector_length ) )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    batch_size = x.size(0)\n",
        "    # (batch_size, num_in_caps, in_vector_length) -> (batch_size, 1, num_in_caps, in_vector_length, 1)\n",
        "    x = x.unsqueeze(1).unsqueeze(4)\n",
        "    #\n",
        "    # W @ x =\n",
        "    # (1, num_output_caps, num_in_caps, out_vector_length, in_vector_length) @ (batch_size, 1, num_in_caps, in_vector_length, 1) =\n",
        "    # (batch_size, num_out_caps, num_in_caps, out_vector_length, 1)\n",
        "    u_hat = torch.matmul(self.W, x)\n",
        "    # (batch_size, num_out_caps, num_in_caps, out_vector_length)\n",
        "    u_hat = u_hat.squeeze(-1)\n",
        "    # detach u_hat during routing iterations to prevent gradients from flowing\n",
        "    temp_u_hat = u_hat.detach()\n",
        "\n",
        "    '''\n",
        "    Procedure 1: Routing algorithm\n",
        "    '''\n",
        "    b = torch.zeros(batch_size, self.num_out_caps, self.num_in_caps, 1).to(dev)\n",
        "\n",
        "    for route_iter in range(self.num_routing-1):\n",
        "      # (batch_size, num_out_caps, num_in_caps, 1) -> Softmax along num_out_caps\n",
        "      c = F.softmax(b, dim=1)\n",
        "\n",
        "      # element-wise multiplication\n",
        "      # (batch_size, num_out_caps, num_in_caps, 1) * (batch_size, num_in_caps, num_out_caps, out_vector_length) ->\n",
        "      # (batch_size, num_out_caps, num_in_caps, out_vector_length) sum across num_in_caps ->\n",
        "      # (batch_size, num_out_caps, out_vector_length)\n",
        "      s = (c * temp_u_hat).sum(dim=2)\n",
        "      # apply \"squashing\" non-linearity along dim_caps\n",
        "      v = squash(s)\n",
        "      # dot product agreement between the current output vj and the prediction uj|i\n",
        "      # (batch_size, num_out_caps, num_in_caps, out_vector_length) @ (batch_size, num_out_caps, out_vector_length, 1)\n",
        "      # -> (batch_size, num_out_caps, num_in_caps, 1)\n",
        "      uv = torch.matmul(temp_u_hat, v.unsqueeze(-1))\n",
        "      b += uv\n",
        "\n",
        "    # last iteration is done on the original u_hat, without the routing weights update\n",
        "    c = F.softmax(b, dim=1)\n",
        "    s = (c * u_hat).sum(dim=2)\n",
        "    # apply \"squashing\" non-linearity along dim_caps\n",
        "    v = squash(s)\n",
        "\n",
        "    return v"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZmQKyYPSQST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Reconstruction(nn.Module):\n",
        "    def __init__(self, num_classes, vector_length):\n",
        "      super().__init__()\n",
        "      \n",
        "      self.fc_layer = nn.Sequential(\n",
        "        nn.Linear(num_classes*vector_length, 64),\n",
        "        nn.ReLU()\n",
        "      )\n",
        "\n",
        "      self.reconstruction_layers = nn.Sequential(\n",
        "          nn.ConvTranspose2d(1, 128, kernel_size=5, padding=2, stride=11),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.ConvTranspose2d(128, 64, kernel_size=5, padding=2, stride=4, output_padding=(1,1)),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.Conv2d(64, 3, kernel_size=5, padding=7, stride=1),\n",
        "          nn.Sigmoid()\n",
        "    )\n",
        "        \n",
        "    def forward(self, x):\n",
        "      x = self.fc_layer(x)\n",
        "      x = x.view(x.size(0), 1, 8, 8)\n",
        "      x = self.reconstruction_layers(x)\n",
        "      return x"
      ],
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qWxbVp1SRBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CapsNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "      super().__init__()\n",
        "      self.conv_layer = nn.Sequential(\n",
        "          nn.Conv2d(3, 64, kernel_size=5, padding=2, stride=4),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.MaxPool2d(kernel_size=5, padding=2, stride=2)\n",
        "      )\n",
        "      self.primary_caps = PrimaryCapsules(in_channels=64, out_channels=128, vector_length=8, kernel_size=5, padding=2, stride=1)\n",
        "      self.digit_caps = nn.Sequential(\n",
        "        RoutingCapsules(in_vector_length=8, num_in_caps=25600, num_out_caps=20, out_vector_length=16, num_routing=3),\n",
        "        RoutingCapsules(in_vector_length=16, num_in_caps=20, num_out_caps=num_classes, out_vector_length=16, num_routing=3)\n",
        "      )\n",
        "      self.reconstruction_layer = Reconstruction(num_classes=num_classes, vector_length=16)\n",
        "    \n",
        "    '''\n",
        "    def capsule_average_pooling(self, x):\n",
        "      height = x.size(3)\n",
        "      width = x.size(4)\n",
        "      x = x.sum(dim=4).sum(dim=3)\n",
        "      x = x / (height * width)\n",
        "      return x\n",
        "    '''\n",
        "    '''\n",
        "    def score(self, x):\n",
        "      return torch.sqrt((x ** 2).sum(dim=2))\n",
        "    '''\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv_layer(x)\n",
        "      x = self.primary_caps(x)\n",
        "      x = self.digit_caps(x)\n",
        "      scores = torch.norm(x,dim=-1)\n",
        "      x = x.view(x.size(0), x.size(1) * x.size(2))\n",
        "      reconstructions = self.reconstruction_layer(x)\n",
        "      return scores, reconstructions"
      ],
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgpgQfZxvHSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def margin_loss(pred, labels, m_plus=0.9, m_minus=0.1, loss_lambda=0.5):\n",
        "  one_hot_labels = F.one_hot(labels,num_classes = num_classes)\n",
        "  loss = one_hot_labels * F.relu(m_plus - pred)**2 + loss_lambda * (1 - one_hot_labels) * F.relu(pred - m_minus)**2\n",
        "  loss = loss.sum(dim=1)\n",
        "  #loss = loss * weights[labels]\n",
        "  return loss.mean()"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9EcOQTmYI3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CapsNet(num_classes=num_classes)\n",
        "model = model.to(dev)"
      ],
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bghnqtQeaxam",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1cb8ce9c-2d7a-4b8e-ed7e-e75f13ed6a42"
      },
      "source": [
        "batch,labels = next(iter(train_loader))\n",
        "batch = batch.to(dev)\n",
        "labels = labels.to(dev)\n",
        "scores, reconstructions = model(batch)\n",
        "print(scores.size())\n",
        "print(reconstructions.size())"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 8])\n",
            "torch.Size([4, 3, 320, 320])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_iemIRmlwd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, dev, lr=0.001, reconstruction_loss_scale=5e-4):\n",
        "    try:\n",
        "        # Create model\n",
        "        model = CapsNet(num_classes=num_classes)\n",
        "        model = model.to(dev)\n",
        "        # Optimizer\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "        # Initialize history\n",
        "        history_loss = {\"train\": [], \"val\": [], \"test\": []}\n",
        "        history_accuracy = {\"train\": [], \"val\": [], \"test\": []}\n",
        "        # Initialize best validation accuracy and test accuracy at best validation accuracy\n",
        "        best_val_accuracy = 0.0\n",
        "        test_accuracy_at_best_val = 0.0\n",
        "        batch_confusion_matrix = torch.zeros(num_classes, num_classes , dtype=torch.int64).to(dev)\n",
        "        # Process each epoch\n",
        "        for epoch in range(epochs):\n",
        "            # Initialize epoch variables\n",
        "            sum_loss = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "            sum_accuracy = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "            confusion_matrix = {\"train\": torch.zeros(num_classes, num_classes , dtype=torch.int64).to(dev), \"val\": torch.zeros(num_classes, num_classes , dtype=torch.int64).to(dev), \"test\": torch.zeros(num_classes, num_classes , dtype=torch.int64).to(dev)}\n",
        "            # Process each split\n",
        "            for split in [\"train\", \"val\", \"test\"]:\n",
        "                if split == \"train\":\n",
        "                  model.train()\n",
        "                else:\n",
        "                  model.eval()\n",
        "                # Process each batch\n",
        "                for (input, labels) in loaders[split]:\n",
        "                    # Move to CUDA\n",
        "                    input = input.to(dev)\n",
        "                    labels = labels.to(dev)\n",
        "                    # Reset gradients\n",
        "                    optimizer.zero_grad()\n",
        "                    # Compute output\n",
        "                    pred, reconstructions = model(input)\n",
        "                    #score_loss = F.cross_entropy(pred, labels, weight=weights)\n",
        "                    score_loss = margin_loss(pred, labels, m_plus=0.9, m_minus=0.1, loss_lambda=0.5)\n",
        "                    reconstruction_loss = F.mse_loss(input, reconstructions) * reconstruction_loss_scale\n",
        "                    loss = score_loss + reconstruction_loss\n",
        "                    # Update loss\n",
        "                    sum_loss[split] += loss.item()\n",
        "                    # Check parameter update\n",
        "                    if split == \"train\":\n",
        "                        # Compute gradients\n",
        "                        loss.backward()\n",
        "                        # Optimize\n",
        "                        optimizer.step()\n",
        "                    # Compute accuracy\n",
        "                    _,pred_labels = pred.max(1)\n",
        "                    batch_accuracy = (pred_labels == labels).sum().item()/input.size(0)\n",
        "                    # Update accuracy\n",
        "                    sum_accuracy[split] += batch_accuracy\n",
        "                    #Update Confusion Matrix\n",
        "                    for label, pred in zip(labels.view(-1), pred_labels.view(-1)):\n",
        "                      confusion_matrix[split][label, pred] += 1\n",
        "            # Compute epoch loss/accuracy\n",
        "            epoch_loss = {split: sum_loss[split]/len(loaders[split]) for split in [\"train\", \"val\", \"test\"]}\n",
        "            epoch_accuracy = {split: sum_accuracy[split]/len(loaders[split]) for split in [\"train\", \"val\", \"test\"]}\n",
        "            # Update history\n",
        "            for split in [\"train\", \"val\", \"test\"]:\n",
        "                history_loss[split].append(epoch_loss[split])\n",
        "                history_accuracy[split].append(epoch_accuracy[split])\n",
        "            # Print info\n",
        "            print(f\"Epoch {epoch+1}:\",\n",
        "                  f\"TrL={epoch_loss['train']:.4f},\",\n",
        "                  f\"TrA={epoch_accuracy['train']:.4f},\",\n",
        "                  f\"VL={epoch_loss['val']:.4f},\",\n",
        "                  f\"VA={epoch_accuracy['val']:.4f},\",\n",
        "                  f\"TeL={epoch_loss['test']:.4f},\",\n",
        "                  f\"TeA={epoch_accuracy['test']:.4f},\\n\"\n",
        "                )\n",
        "            # Check if we obtained the best validation accuracy\n",
        "            if best_val_accuracy == 0.0 or epoch_accuracy[\"val\"] > best_val_accuracy:\n",
        "              # Update best validation accuracy and test accuracy at best validation\n",
        "              best_val_accuracy = epoch_accuracy[\"val\"]\n",
        "              test_accuracy_at_best_val = epoch_accuracy[\"test\"]\n",
        "            #Print per-class accuracy\n",
        "            print(f\"Training per-class accuracy: {(confusion_matrix['train'].diag()/confusion_matrix['train'].sum(1).double()).tolist()}\")\n",
        "            print(f\"Validation per-class accuracy: {(confusion_matrix['val'].diag()/confusion_matrix['val'].sum(1).double()).tolist()}\")\n",
        "            print(f\"Test per-class accuracy: {(confusion_matrix['test'].diag()/confusion_matrix['test'].sum(1).double()).tolist()} \\n\")\n",
        "            print(f\"----------------------------------\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Interrupted\")\n",
        "    finally:\n",
        "        # Print best validation accuracy and test accuracy at best validation \n",
        "        print(f\"Best validation accuracy: {best_val_accuracy}\")\n",
        "        print(f\"Test accuracy at best validation: {test_accuracy_at_best_val}\")\n",
        "        # Plot loss\n",
        "        plt.title(\"Loss\")\n",
        "        for split in [\"train\", \"val\", \"test\"]:\n",
        "            plt.plot(history_loss[split], label=split)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        # Plot accuracy\n",
        "        plt.title(\"Accuracy\")\n",
        "        for split in [\"train\", \"val\", \"test\"]:\n",
        "            plt.plot(history_accuracy[split], label=split)\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgcTyH7emXjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d09abaa6-dde3-4248-dd9a-e9dced0a825f"
      },
      "source": [
        "train(100, dev, lr=0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: TrL=0.8760, TrA=0.4051, VL=0.3892, VA=0.4455, TeL=0.3850, TeA=0.4831,\n",
            "\n",
            "Training per-class accuracy: [0.77, 0.0, 0.0, 0.021505376344086023, 0.0, 0.0, 0.1875, 0.0]\n",
            "Validation per-class accuracy: [0.41, 0.0, 0.0, 0.043478260869565216, 0.0, 0.0, 0.835820895522388, 0.0]\n",
            "Test per-class accuracy: [0.4485981308411215, 0.08333333333333333, 0.0, 0.061224489795918366, 0.0, 0.0, 0.8827586206896552, 0.0] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 2: TrL=0.4352, TrA=0.4361, VL=0.4102, VA=0.4682, TeL=0.4183, TeA=0.4555,\n",
            "\n",
            "Training per-class accuracy: [0.7, 0.043478260869565216, 0.0, 0.10752688172043011, 0.0, 0.0, 0.35294117647058826, 0.023809523809523808]\n",
            "Validation per-class accuracy: [0.96, 0.4, 0.0, 0.0, 0.3333333333333333, 0.0, 0.05970149253731343, 0.0]\n",
            "Test per-class accuracy: [0.9813084112149533, 0.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.027586206896551724, 0.0] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 3: TrL=0.3721, TrA=0.4671, VL=0.4170, VA=0.3727, TeL=0.4185, TeA=0.3686,\n",
            "\n",
            "Training per-class accuracy: [0.77, 0.21739130434782608, 0.03225806451612903, 0.07526881720430108, 0.0, 0.0625, 0.34191176470588236, 0.023809523809523808]\n",
            "Validation per-class accuracy: [0.18, 0.4, 0.14285714285714285, 0.043478260869565216, 0.0, 0.0, 0.8955223880597015, 0.0]\n",
            "Test per-class accuracy: [0.16355140186915887, 0.0, 0.3125, 0.04081632653061224, 0.16666666666666666, 0.0, 0.903448275862069, 0.0] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 4: TrL=0.3500, TrA=0.4768, VL=0.3334, VA=0.5273, TeL=0.3245, TeA=0.5508,\n",
            "\n",
            "Training per-class accuracy: [0.7725, 0.17391304347826086, 0.0, 0.13978494623655913, 0.14285714285714285, 0.125, 0.34191176470588236, 0.047619047619047616]\n",
            "Validation per-class accuracy: [0.9, 0.2, 0.0, 0.0, 0.0, 0.0, 0.373134328358209, 0.0]\n",
            "Test per-class accuracy: [0.9299065420560748, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.41379310344827586, 0.0] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 5: TrL=0.3326, TrA=0.5262, VL=0.3822, VA=0.4591, TeL=0.3849, TeA=0.4428,\n",
            "\n",
            "Training per-class accuracy: [0.7925, 0.34782608695652173, 0.06451612903225806, 0.22580645161290322, 0.21428571428571427, 0.1875, 0.41544117647058826, 0.047619047619047616]\n",
            "Validation per-class accuracy: [0.34, 0.2, 0.0, 0.08695652173913043, 0.6666666666666666, 0.0, 0.9253731343283582, 0.0]\n",
            "Test per-class accuracy: [0.2850467289719626, 0.3333333333333333, 0.0, 0.14285714285714285, 0.3333333333333333, 0.0, 0.9310344827586207, 0.0] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 6: TrL=0.3071, TrA=0.5392, VL=0.3270, VA=0.5182, TeL=0.3174, TeA=0.5572,\n",
            "\n",
            "Training per-class accuracy: [0.7825, 0.6521739130434783, 0.03225806451612903, 0.16129032258064516, 0.2857142857142857, 0.375, 0.4522058823529412, 0.09523809523809523]\n",
            "Validation per-class accuracy: [0.87, 0.2, 0.0, 0.2608695652173913, 0.0, 0.3333333333333333, 0.2835820895522388, 0.0]\n",
            "Test per-class accuracy: [0.9299065420560748, 0.16666666666666666, 0.0, 0.3469387755102041, 0.0, 0.2857142857142857, 0.296551724137931, 0.0] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 7: TrL=0.2796, TrA=0.5762, VL=0.3024, VA=0.5591, TeL=0.2989, TeA=0.5445,\n",
            "\n",
            "Training per-class accuracy: [0.845, 0.5652173913043478, 0.06451612903225806, 0.24731182795698925, 0.2857142857142857, 0.3125, 0.4522058823529412, 0.11904761904761904]\n",
            "Validation per-class accuracy: [0.8, 0.4, 0.14285714285714285, 0.043478260869565216, 0.0, 0.3333333333333333, 0.5671641791044776, 0.0]\n",
            "Test per-class accuracy: [0.7523364485981309, 0.4166666666666667, 0.0625, 0.061224489795918366, 0.16666666666666666, 0.7142857142857143, 0.5379310344827586, 0.13636363636363635] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 8: TrL=0.2506, TrA=0.6398, VL=0.3765, VA=0.4000, TeL=0.3640, TeA=0.4089,\n",
            "\n",
            "Training per-class accuracy: [0.865, 0.8695652173913043, 0.1935483870967742, 0.3548387096774194, 0.42857142857142855, 0.375, 0.5183823529411765, 0.2857142857142857]\n",
            "Validation per-class accuracy: [0.2, 0.2, 0.0, 0.043478260869565216, 0.3333333333333333, 0.0, 0.9701492537313433, 0.0]\n",
            "Test per-class accuracy: [0.21495327102803738, 0.08333333333333333, 0.0, 0.04081632653061224, 0.16666666666666666, 0.2857142857142857, 0.9517241379310345, 0.13636363636363635] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 9: TrL=0.2424, TrA=0.6532, VL=0.2798, VA=0.5909, TeL=0.2640, TeA=0.6314,\n",
            "\n",
            "Training per-class accuracy: [0.82, 0.782608695652174, 0.1935483870967742, 0.44086021505376344, 0.5, 0.625, 0.5882352941176471, 0.2857142857142857]\n",
            "Validation per-class accuracy: [0.84, 0.4, 0.2857142857142857, 0.17391304347826086, 0.6666666666666666, 0.0, 0.5223880597014925, 0.1]\n",
            "Test per-class accuracy: [0.8457943925233645, 0.4166666666666667, 0.125, 0.2857142857142857, 0.3333333333333333, 0.5714285714285714, 0.5517241379310345, 0.45454545454545453] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 10: TrL=0.2073, TrA=0.7160, VL=0.2763, VA=0.6091, TeL=0.2550, TeA=0.6504,\n",
            "\n",
            "Training per-class accuracy: [0.8525, 0.9565217391304348, 0.45161290322580644, 0.5483870967741935, 0.7142857142857143, 0.75, 0.6470588235294118, 0.2857142857142857]\n",
            "Validation per-class accuracy: [0.75, 0.2, 0.2857142857142857, 0.2608695652173913, 0.6666666666666666, 0.3333333333333333, 0.6865671641791045, 0.1]\n",
            "Test per-class accuracy: [0.7383177570093458, 0.3333333333333333, 0.1875, 0.3673469387755102, 0.3333333333333333, 0.8571428571428571, 0.7034482758620689, 0.5909090909090909] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 11: TrL=0.1869, TrA=0.7608, VL=0.2870, VA=0.6091, TeL=0.2689, TeA=0.6603,\n",
            "\n",
            "Training per-class accuracy: [0.875, 0.9565217391304348, 0.3870967741935484, 0.6129032258064516, 0.6428571428571429, 0.875, 0.7205882352941176, 0.42857142857142855]\n",
            "Validation per-class accuracy: [0.72, 0.2, 0.2857142857142857, 0.21739130434782608, 0.6666666666666666, 0.3333333333333333, 0.7014925373134329, 0.3]\n",
            "Test per-class accuracy: [0.7663551401869159, 0.5, 0.125, 0.3877551020408163, 0.3333333333333333, 0.8571428571428571, 0.6620689655172414, 0.7272727272727273] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 12: TrL=0.1609, TrA=0.7814, VL=0.2588, VA=0.6545, TeL=0.2441, TeA=0.6815,\n",
            "\n",
            "Training per-class accuracy: [0.8775, 0.9565217391304348, 0.3225806451612903, 0.6129032258064516, 0.7142857142857143, 0.9375, 0.7683823529411765, 0.5238095238095238]\n",
            "Validation per-class accuracy: [0.84, 0.2, 0.2857142857142857, 0.5217391304347826, 0.0, 0.3333333333333333, 0.582089552238806, 0.4]\n",
            "Test per-class accuracy: [0.8598130841121495, 0.4166666666666667, 0.125, 0.46938775510204084, 0.16666666666666666, 0.7142857142857143, 0.593103448275862, 0.6818181818181818] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 13: TrL=0.1347, TrA=0.8584, VL=0.3124, VA=0.5636, TeL=0.2844, TeA=0.5558,\n",
            "\n",
            "Training per-class accuracy: [0.9425, 1.0, 0.6129032258064516, 0.7526881720430108, 0.7142857142857143, 0.9375, 0.8235294117647058, 0.6428571428571429]\n",
            "Validation per-class accuracy: [0.48, 0.2, 0.2857142857142857, 0.21739130434782608, 0.0, 0.0, 0.9701492537313433, 0.2]\n",
            "Test per-class accuracy: [0.4158878504672897, 0.4166666666666667, 0.0625, 0.3469387755102041, 0.16666666666666666, 0.2857142857142857, 0.9448275862068966, 0.45454545454545453] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 14: TrL=0.1246, TrA=0.8572, VL=0.2693, VA=0.6682, TeL=0.2400, TeA=0.6871,\n",
            "\n",
            "Training per-class accuracy: [0.92, 1.0, 0.6451612903225806, 0.7849462365591398, 0.7142857142857143, 1.0, 0.8161764705882353, 0.7619047619047619]\n",
            "Validation per-class accuracy: [0.77, 0.4, 0.42857142857142855, 0.43478260869565216, 0.3333333333333333, 0.3333333333333333, 0.7164179104477612, 0.4]\n",
            "Test per-class accuracy: [0.822429906542056, 0.5833333333333334, 0.125, 0.5306122448979592, 0.5, 0.7142857142857143, 0.6344827586206897, 0.5909090909090909] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 15: TrL=0.1009, TrA=0.8924, VL=0.2540, VA=0.6500, TeL=0.2269, TeA=0.6766,\n",
            "\n",
            "Training per-class accuracy: [0.935, 0.9565217391304348, 0.7096774193548387, 0.8064516129032258, 0.7857142857142857, 1.0, 0.8713235294117647, 0.9047619047619048]\n",
            "Validation per-class accuracy: [0.89, 0.4, 0.2857142857142857, 0.34782608695652173, 0.0, 0.0, 0.582089552238806, 0.2]\n",
            "Test per-class accuracy: [0.9112149532710281, 0.5, 0.125, 0.40816326530612246, 0.3333333333333333, 0.7142857142857143, 0.5517241379310345, 0.4090909090909091] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 16: TrL=0.0842, TrA=0.9167, VL=0.2615, VA=0.6455, TeL=0.2276, TeA=0.6857,\n",
            "\n",
            "Training per-class accuracy: [0.965, 1.0, 0.7741935483870968, 0.8924731182795699, 0.7857142857142857, 1.0, 0.8786764705882353, 0.8333333333333334]\n",
            "Validation per-class accuracy: [0.64, 0.4, 0.2857142857142857, 0.6086956521739131, 0.6666666666666666, 0.3333333333333333, 0.7910447761194029, 0.3]\n",
            "Test per-class accuracy: [0.677570093457944, 0.6666666666666666, 0.25, 0.6938775510204082, 0.3333333333333333, 0.7142857142857143, 0.7517241379310344, 0.7272727272727273] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 17: TrL=0.0574, TrA=0.9686, VL=0.2478, VA=0.6818, TeL=0.2207, TeA=0.7225,\n",
            "\n",
            "Training per-class accuracy: [0.9825, 1.0, 1.0, 0.9354838709677419, 0.9285714285714286, 1.0, 0.9485294117647058, 1.0]\n",
            "Validation per-class accuracy: [0.78, 0.4, 0.42857142857142855, 0.4782608695652174, 0.6666666666666666, 0.3333333333333333, 0.7014925373134329, 0.5]\n",
            "Test per-class accuracy: [0.8411214953271028, 0.5833333333333334, 0.125, 0.5918367346938775, 0.6666666666666666, 0.8571428571428571, 0.6620689655172414, 0.7272727272727273] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 18: TrL=0.0445, TrA=0.9709, VL=0.2662, VA=0.6773, TeL=0.2309, TeA=0.7246,\n",
            "\n",
            "Training per-class accuracy: [0.9825, 1.0, 0.967741935483871, 0.956989247311828, 0.9285714285714286, 1.0, 0.9558823529411765, 0.9761904761904762]\n",
            "Validation per-class accuracy: [0.84, 0.2, 0.2857142857142857, 0.6521739130434783, 0.0, 0.3333333333333333, 0.6119402985074627, 0.4]\n",
            "Test per-class accuracy: [0.8504672897196262, 0.5, 0.1875, 0.7346938775510204, 0.3333333333333333, 0.7142857142857143, 0.6344827586206897, 0.6818181818181818] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 19: TrL=0.0392, TrA=0.9798, VL=0.2846, VA=0.6455, TeL=0.2690, TeA=0.6928,\n",
            "\n",
            "Training per-class accuracy: [0.9925, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.9595588235294118, 0.9523809523809523]\n",
            "Validation per-class accuracy: [0.6, 0.4, 0.42857142857142855, 0.6086956521739131, 0.6666666666666666, 0.3333333333333333, 0.7910447761194029, 0.6]\n",
            "Test per-class accuracy: [0.6728971962616822, 0.5833333333333334, 0.125, 0.7346938775510204, 0.5, 0.7142857142857143, 0.7724137931034483, 0.7727272727272727] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 20: TrL=0.0272, TrA=0.9899, VL=0.2337, VA=0.6864, TeL=0.2271, TeA=0.7161,\n",
            "\n",
            "Training per-class accuracy: [0.995, 1.0, 1.0, 0.989247311827957, 1.0, 1.0, 0.9779411764705882, 1.0]\n",
            "Validation per-class accuracy: [0.86, 0.2, 0.42857142857142855, 0.4782608695652174, 0.6666666666666666, 0.3333333333333333, 0.6119402985074627, 0.5]\n",
            "Test per-class accuracy: [0.8785046728971962, 0.5, 0.3125, 0.3469387755102041, 0.5, 0.7142857142857143, 0.6758620689655173, 0.6818181818181818] \n",
            "\n",
            "----------------------------------\n",
            "Epoch 21: TrL=0.0203, TrA=0.9955, VL=0.2526, VA=0.6818, TeL=0.2280, TeA=0.7140,\n",
            "\n",
            "Training per-class accuracy: [1.0, 1.0, 1.0, 0.989247311827957, 1.0, 1.0, 0.9926470588235294, 0.9761904761904762]\n",
            "Validation per-class accuracy: [0.69, 0.4, 0.2857142857142857, 0.5652173913043478, 0.6666666666666666, 0.3333333333333333, 0.8208955223880597, 0.5]\n",
            "Test per-class accuracy: [0.7009345794392523, 0.5833333333333334, 0.25, 0.6326530612244898, 0.5, 1.0, 0.8, 0.8181818181818182] \n",
            "\n",
            "----------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Capsule_Network_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "liZ59nsCr2ry",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U7AN-xvK8RVc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1495689b-ea3a-44d2-abcf-0782c3aa4319"
      },
      "source": [
        "print(f\"CUDA is available? {torch.cuda.is_available()}\")\n",
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available? True\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HddFaBBPs0k6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "831d3c8a-a9d8-4610-df42-793cd4b562a2"
      },
      "source": [
        "drive.mount(\"/content/drive\",True)\n",
        "root_dir = \"/content/drive/My Drive/SB3/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z2ZbRWBjtCy-",
        "colab": {}
      },
      "source": [
        "train_transform = T.Compose([\n",
        "    T.Resize(256),\n",
        "    T.ToTensor()\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ATSMdhMvtH4_",
        "colab": {}
      },
      "source": [
        "train_dataset = ImageFolder(os.path.join(root_dir, \"train\"), transform=train_transform)\n",
        "test_dataset = ImageFolder(os.path.join(root_dir, \"test\"), transform=train_transform)\n",
        "num_train = len(train_dataset)\n",
        "train_idx = list(range(num_train))\n",
        "random.shuffle(train_idx)\n",
        "val_frac = 0.2\n",
        "num_val = int(num_train*val_frac)\n",
        "num_train = num_train - num_val\n",
        "val_idx = train_idx[num_train:]\n",
        "train_idx = train_idx[:num_train]\n",
        "val_dataset = Subset(train_dataset,val_idx)\n",
        "train_dataset = Subset(train_dataset, train_idx)\n",
        "train_loader = DataLoader(train_dataset, batch_size = 4, num_workers=4, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, num_workers=4, shuffle=False)\n",
        "test_loader   = DataLoader(test_dataset,   batch_size = 4, num_workers=4, shuffle=False)\n",
        "loaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"val\" : val_loader,\n",
        "    \"test\": test_loader\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZdhX4e8dtL-g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd8f1f10-dc18-49b3-cb52-cc3e914e52fe"
      },
      "source": [
        "num_classes = len(train_dataset.classes)\n",
        "print(num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1sRHplNeLGCy",
        "colab": {}
      },
      "source": [
        "class ConvCapsLayer(nn.Module):\n",
        "    def __init__(self, in_channel_types, out_channel_types, in_vector_length, out_vector_length, kernel_size, padding, stride, num_iterations, new_height, new_width):\n",
        "      super().__init__()\n",
        "      \n",
        "      self.in_channel_types = in_channel_types\n",
        "      self.out_channel_types = out_channel_types\n",
        "      self.in_vector_length = in_vector_length\n",
        "      self.out_vector_length = out_vector_length\n",
        "      self.kernel_size = kernel_size\n",
        "      self.padding = padding\n",
        "      self.stride = stride\n",
        "      self.num_iterations = num_iterations\n",
        "      self.new_height = new_height\n",
        "      self.new_width = new_width\n",
        "      self.W = nn.Parameter(torch.randn(1, in_channel_types, 1, out_channel_types, out_vector_length, in_vector_length))\n",
        "    \n",
        "    def squash(self, in_tensor):\n",
        "      squared_norm = (in_tensor ** 2).sum(-2, keepdim=True)\n",
        "      out_tensor = squared_norm *  in_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm) + 1e-10)\n",
        "      return out_tensor\n",
        "\n",
        "    def forward(self, x):\n",
        "      batch_size = x.size(0)\n",
        "      y = torch.zeros(batch_size, self.in_vector_length, self.in_channel_types, self.new_height, self.new_width, dtype=torch.float).to(dev)\n",
        "      kernel = torch.ones(1, 1, self.kernel_size, self.kernel_size, dtype=torch.float).to(dev)\n",
        "      for i in range(self.in_vector_length):\n",
        "        for j in range(self.in_channel_types):\n",
        "          y[:,i,j,:,:] = F.conv2d(x[:,i,j,:,:].unsqueeze_(1), kernel, padding=self.padding, stride=self.stride).squeeze(1)\n",
        "\n",
        "      y = y.view(batch_size, self.in_channel_types, self.new_height * self.new_width, -1)\n",
        "      y = torch.stack([y] * self.out_channel_types, dim=3).unsqueeze(5)\n",
        "\n",
        "      W = torch.cat([self.W] * batch_size, dim=0)\n",
        "      c = W @ y\n",
        "\n",
        "      b_ij = torch.zeros(1, self.in_channel_types, c.size(2), self.out_channel_types, 1).to(dev)\n",
        "\n",
        "      for iteration in range(self.num_iterations):\n",
        "        c_ij = F.softmax(b_ij, dim=-2)\n",
        "        c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(5)\n",
        "\n",
        "        s_j = (c_ij * c).sum(dim=1, keepdim=True)\n",
        "        v_j = self.squash(s_j)\n",
        "\n",
        "        if iteration < self.num_iterations - 1:\n",
        "          a_ij = torch.matmul(c.transpose(4, 5), torch.cat([v_j] * self.in_channel_types, dim=1))\n",
        "          b_ij = b_ij + a_ij.squeeze(5).mean(dim=0, keepdim=True)\n",
        "\n",
        "      v_j = v_j.squeeze(1)\n",
        "      v_j = v_j.transpose(3,1).squeeze(4)\n",
        "      v_j = v_j.view(v_j.size(0), v_j.size(1), v_j.size(2), self.new_height, self.new_width)\n",
        "      return v_j"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H438k6GcTxvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Reconstruction(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "      super().__init__()\n",
        "      \n",
        "      self.fc_layer = nn.Sequential(\n",
        "        nn.Linear(num_classes*16, 80),\n",
        "        nn.ReLU(inplace=True)\n",
        "      )\n",
        "\n",
        "      self.reconstruction_layers = nn.Sequential(\n",
        "          nn.ConvTranspose2d(1, 128, kernel_size=5, padding=2, stride=8, output_padding = (7,7)),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.ConvTranspose2d(128, 64, kernel_size=5, padding=2, stride=8, output_padding = (7,7)),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Conv2d(64, 3, kernel_size=5, padding=2, stride=1),\n",
        "          nn.ReLU(inplace=True)\n",
        "    )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc_layer(x)\n",
        "        print(x.size())\n",
        "        x = x.view(x.size(0), 1, 8, 10)\n",
        "        x = self.reconstruction_layers(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t3J6xWcxzzZj",
        "colab": {}
      },
      "source": [
        "class CapsNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=5, padding=2, stride=2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        self.conv_capsule_layers = nn.Sequential(\n",
        "            ConvCapsLayer(in_channel_types = 1, out_channel_types = 2, in_vector_length = 16, out_vector_length = 16, kernel_size = 5, padding = 2, stride = 2, num_iterations = 1, new_height = 64, new_width = 64),\n",
        "            ConvCapsLayer(in_channel_types = 2, out_channel_types = 4, in_vector_length = 16, out_vector_length = 16, kernel_size = 5, padding = 2, stride = 1, num_iterations = 3, new_height = 64, new_width = 64),\n",
        "            ConvCapsLayer(in_channel_types = 4, out_channel_types = 4, in_vector_length = 16, out_vector_length = 32, kernel_size = 5, padding = 2, stride = 2, num_iterations = 3, new_height = 32, new_width = 32),\n",
        "            ConvCapsLayer(in_channel_types = 4, out_channel_types = 8, in_vector_length = 32, out_vector_length = 32, kernel_size = 5, padding = 2, stride = 1, num_iterations = 3, new_height = 32, new_width = 32),\n",
        "            ConvCapsLayer(in_channel_types = 8, out_channel_types = 8, in_vector_length = 32, out_vector_length = 64, kernel_size = 5, padding = 2, stride = 2, num_iterations = 3, new_height = 16, new_width = 16),\n",
        "            ConvCapsLayer(in_channel_types = 8, out_channel_types = 8, in_vector_length = 64, out_vector_length = 32, kernel_size = 5, padding = 2, stride = 1, num_iterations = 3, new_height = 16, new_width = 16),\n",
        "            ConvCapsLayer(in_channel_types = 8, out_channel_types = num_classes, in_vector_length = 32, out_vector_length = 16, kernel_size = 5, padding = 2, stride = 2, num_iterations = 3, new_height = 8, new_width = 8)\n",
        "        )\n",
        "\n",
        "        self.reconstruction_layer = Reconstruction(num_classes=2)\n",
        "\n",
        "    def capsule_average_pooling(self, x):\n",
        "      height = x.size(3)\n",
        "      width = x.size(4)\n",
        "      x = x.sum(dim=4).sum(dim=3)\n",
        "      x = x / (height * width)\n",
        "      return x\n",
        "    \n",
        "    def score(self, x):\n",
        "      return torch.sqrt((x ** 2).sum(dim=2))\n",
        "    \n",
        "    def forward(self, x):\n",
        "      x = self.conv_layers(x)\n",
        "      x = x.unsqueeze(2)\n",
        "      x = self.conv_capsule_layers(x)\n",
        "      x = x.transpose(1, 2)\n",
        "      x = self.capsule_average_pooling(x)\n",
        "      scores = self.score(x)\n",
        "      x = x.view(x.size(0), x.size(1) * x.size(2))\n",
        "      reconstructions = self.reconstruction_layer(x)\n",
        "      return scores, reconstructions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qtTivCTQ1Uuo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d4ab7954-3dd5-46b3-c61f-2c095be3dff8"
      },
      "source": [
        "batch,labels = next(iter(train_loader))\n",
        "batch = batch.to(dev)\n",
        "labels = labels.to(dev)\n",
        "model = CapsNet(num_classes=2)\n",
        "model = model.to(dev)\n",
        "scores, reconstructions = model(batch)\n",
        "print(reconstructions.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 80])\n",
            "torch.Size([4, 3, 512, 640])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIjFpX3vMYVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create optimizer\n",
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyMuXrGCEtHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, dev, lr=0.001):\n",
        "  try:\n",
        "    model = CapsNet(num_classes=2)\n",
        "    model = model.to(dev)\n",
        "    history_loss = {\"train\": [], \"val\": [], \"test\": []}\n",
        "    history_accuracy = {\"train\": [], \"val\": [], \"test\": []}\n",
        "    for epoch in range(epochs):\n",
        "      sum_loss = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "      sum_accuracy= {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "      for split in [\"train\",\"val\",\"test\"]:\n",
        "        if split == \"train\":\n",
        "          model.train()\n",
        "        else:\n",
        "          model.eval()\n",
        "        for (input,labels) in loaders[split]:\n",
        "          input = input.to(dev)\n",
        "          labels = labels.to(dev)\n",
        "          optimizer.zero_grad()\n",
        "          pred = model(input)\n",
        "          loss = F.cross_entropy(pred,labels)\n",
        "          sum_loss[split] += loss.item()\n",
        "          if split == \"train\":\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "          _,pred_labels = pred.max(1)\n",
        "          batch_accuracy = (pred_labels == labels).sum().item()/input.size(0)\n",
        "          sum_accuracy[split] += batch_accuracy\n",
        "      epoch_loss = {split: sum_loss[split]/len(loaders[split]) for split in [\"train\",\"val\",\"test\"]}\n",
        "      epoch_accuracy = {split: sum_accuracy[split]/len(loaders[split]) for split in [\"train\",\"val\",\"test\"]}\n",
        "      for split in [\"train\",\"val\",\"test\"]:\n",
        "        history_loss[split].append(epoch_loss[split])\n",
        "        history_accuracy[split].append(epoch_accuracy[split])\n",
        "      print(f\"Epoch {epoch+1}:\",\n",
        "            f\"TrL={epoch_loss['train']:.4f},\",\n",
        "            f\"TrA={epoch_accuracy['train']:.4f},\"\n",
        "            f\"VL={epoch_loss['val']:.4f},\"\n",
        "            f\"VA={epoch_accuracy['val']:.4f},\"\n",
        "            f\"TeL={epoch_loss['test']:.4f},\"\n",
        "            f\"TeA={epoch_accuracy['test']:.4f},\")\n",
        "  except KeyboardInterrupt:\n",
        "    print(\"Interrupted\")\n",
        "  finally:\n",
        "    plt.title(\"Loss\")\n",
        "    for split in [\"train\",\"val\",\"test\"]:\n",
        "      plt.plot(history_loss[split],label = split)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.title(\"Accuracy\")\n",
        "    for split in [\"train\",\"val\",\"test\"]:\n",
        "      plt.plot(history_accuracy[split], label = split)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Capsule_Network_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "liZ59nsCr2ry",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import torch.optim as optim\n",
        "import time"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U7AN-xvK8RVc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d4f5b117-8d32-46e6-ac91-d0dfe32dc298"
      },
      "source": [
        "print(f\"CUDA is available? {torch.cuda.is_available()}\")\n",
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(dev)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available? True\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HddFaBBPs0k6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "47f7d294-8d1c-435b-9fb1-e39fa22484f3"
      },
      "source": [
        "drive.mount(\"/content/drive\",True)\n",
        "root_dir = \"/content/drive/My Drive/SB3/\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z2ZbRWBjtCy-",
        "colab": {}
      },
      "source": [
        "train_transform = T.Compose([\n",
        "    T.Resize(256),\n",
        "    T.ToTensor()\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PeKzVOhXRFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d8a0a7a-b811-4e30-a813-cd1cf26750f9"
      },
      "source": [
        "train_dataset = ImageFolder(os.path.join(root_dir, \"train\"), transform=train_transform)\n",
        "test_dataset = ImageFolder(os.path.join(root_dir, \"test\"), transform=train_transform)\n",
        "num_classes = len(train_dataset.classes)\n",
        "print(num_classes)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ATSMdhMvtH4_",
        "colab": {}
      },
      "source": [
        "num_train = len(train_dataset)\n",
        "train_idx = list(range(num_train))\n",
        "random.shuffle(train_idx)\n",
        "val_frac = 0.2\n",
        "num_val = int(num_train*val_frac)\n",
        "num_train = num_train - num_val\n",
        "val_idx = train_idx[num_train:]\n",
        "train_idx = train_idx[:num_train]\n",
        "val_dataset = Subset(train_dataset,val_idx)\n",
        "train_dataset = Subset(train_dataset, train_idx)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvmXS4H5XcVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=4, num_workers=4, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, num_workers=4, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset,   batch_size=4, num_workers=4, shuffle=False)\n",
        "loaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"val\" : val_loader,\n",
        "    \"test\": test_loader\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1sRHplNeLGCy",
        "colab": {}
      },
      "source": [
        "class ConvCapsLayer(nn.Module):\n",
        "    def __init__(self, in_channel_types, out_channel_types, in_vector_length, out_vector_length, kernel_size, padding, stride, num_iterations, new_height, new_width):\n",
        "      super().__init__()\n",
        "      \n",
        "      self.in_channel_types = in_channel_types\n",
        "      self.out_channel_types = out_channel_types\n",
        "      self.in_vector_length = in_vector_length\n",
        "      self.out_vector_length = out_vector_length\n",
        "      self.kernel_size = kernel_size\n",
        "      self.padding = padding\n",
        "      self.stride = stride\n",
        "      self.num_iterations = num_iterations\n",
        "      self.new_height = new_height\n",
        "      self.new_width = new_width\n",
        "      self.W = nn.Parameter(torch.randn(1, in_channel_types, 1, out_channel_types, out_vector_length, in_vector_length))\n",
        "    \n",
        "    def squash(self, in_tensor):\n",
        "      squared_norm = (in_tensor ** 2).sum(-2, keepdim=True)\n",
        "      out_tensor = squared_norm / (1 + squared_norm) * in_tensor / (torch.sqrt(squared_norm) + 1e-8)\n",
        "      return out_tensor\n",
        "\n",
        "    def forward(self, x):\n",
        "      batch_size = x.size(0)\n",
        "      y = torch.zeros(batch_size, self.in_vector_length, self.in_channel_types, self.new_height, self.new_width, dtype=torch.float).to(dev)\n",
        "      kernel = torch.ones(1, 1, self.kernel_size, self.kernel_size, dtype=torch.float).to(dev)\n",
        "      for i in range(self.in_vector_length):\n",
        "        for j in range(self.in_channel_types):\n",
        "          y[:,i,j,:,:] = F.conv2d(x[:,i,j,:,:].unsqueeze_(1), kernel, padding=self.padding, stride=self.stride).squeeze(1)\n",
        "\n",
        "      y = y.view(batch_size, self.in_channel_types, self.new_height * self.new_width, -1)\n",
        "      y = torch.stack([y] * self.out_channel_types, dim=3).unsqueeze(5)\n",
        "\n",
        "      c = self.W @ y\n",
        "\n",
        "      temp_c = c.detach()\n",
        "\n",
        "      b_ij = torch.zeros(batch_size, self.in_channel_types, temp_c.size(2), self.out_channel_types, 1).to(dev)\n",
        "\n",
        "      for iteration in range(self.num_iterations - 1):\n",
        "        c_ij = F.softmax(b_ij, dim=-2).unsqueeze(5)\n",
        "        \n",
        "        s_j = (c_ij * temp_c).sum(dim=1, keepdim=True)\n",
        "        v_j = self.squash(s_j)\n",
        "\n",
        "        a_ij = torch.matmul(temp_c.transpose(4, 5), torch.cat([v_j] * self.in_channel_types, dim=1))\n",
        "        b_ij = b_ij + a_ij.squeeze(5).mean(dim=0, keepdim=True)\n",
        "      \n",
        "      c_ij = F.softmax(b_ij, dim=-2).unsqueeze(5)\n",
        "      \n",
        "      s_j = (c_ij * c).sum(dim=1, keepdim=True)\n",
        "      v_j = self.squash(s_j)\n",
        "  \n",
        "      v_j = v_j.squeeze(1)\n",
        "      v_j = v_j.transpose(3,1).squeeze(4)\n",
        "      v_j = v_j.view(v_j.size(0), v_j.size(1), v_j.size(2), self.new_height, self.new_width)\n",
        "      return v_j"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H438k6GcTxvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Reconstruction(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "      super().__init__()\n",
        "      \n",
        "      self.fc_layer = nn.Sequential(\n",
        "        nn.Linear(num_classes*16, 64),\n",
        "        nn.ReLU()\n",
        "      )\n",
        "\n",
        "      self.reconstruction_layers = nn.Sequential(\n",
        "          nn.ConvTranspose2d(1, 128, kernel_size=5, padding=2, stride=9),\n",
        "          nn.ReLU(),\n",
        "          nn.ConvTranspose2d(128, 64, kernel_size=5, padding=1, stride=4, output_padding=(1,1)),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(64, 3, kernel_size=5, padding=2, stride=1),\n",
        "          nn.ReLU()\n",
        "    )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc_layer(x)\n",
        "        x = x.view(x.size(0), 1, 8, 8)\n",
        "        x = self.reconstruction_layers(x)\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t3J6xWcxzzZj",
        "colab": {}
      },
      "source": [
        "class CapsNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=5, padding=2, stride=2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.conv_capsule_layers = nn.Sequential(\n",
        "            ConvCapsLayer(in_channel_types = 1, out_channel_types = 2, in_vector_length = 16, out_vector_length = 16, kernel_size = 5, padding = 2, stride = 2, num_iterations = 1, new_height = 64, new_width = 64),\n",
        "            ConvCapsLayer(in_channel_types = 2, out_channel_types = 4, in_vector_length = 16, out_vector_length = 16, kernel_size = 5, padding = 2, stride = 1, num_iterations = 3, new_height = 64, new_width = 64),\n",
        "            ConvCapsLayer(in_channel_types = 4, out_channel_types = 4, in_vector_length = 16, out_vector_length = 32, kernel_size = 5, padding = 2, stride = 2, num_iterations = 3, new_height = 32, new_width = 32),\n",
        "            ConvCapsLayer(in_channel_types = 4, out_channel_types = 8, in_vector_length = 32, out_vector_length = 32, kernel_size = 5, padding = 2, stride = 1, num_iterations = 3, new_height = 32, new_width = 32),\n",
        "            ConvCapsLayer(in_channel_types = 8, out_channel_types = 8, in_vector_length = 32, out_vector_length = 64, kernel_size = 5, padding = 2, stride = 2, num_iterations = 3, new_height = 16, new_width = 16),\n",
        "            ConvCapsLayer(in_channel_types = 8, out_channel_types = 8, in_vector_length = 64, out_vector_length = 32, kernel_size = 5, padding = 2, stride = 1, num_iterations = 3, new_height = 16, new_width = 16),\n",
        "            ConvCapsLayer(in_channel_types = 8, out_channel_types = num_classes, in_vector_length = 32, out_vector_length = 16, kernel_size = 5, padding = 2, stride = 2, num_iterations = 3, new_height = 8, new_width = 8)\n",
        "        )\n",
        "\n",
        "        self.reconstruction_layer = Reconstruction(num_classes)\n",
        "\n",
        "    def capsule_average_pooling(self, x):\n",
        "      height = x.size(3)\n",
        "      width = x.size(4)\n",
        "      x = x.sum(dim=4).sum(dim=3)\n",
        "      x = x / (height * width)\n",
        "      return x\n",
        "    \n",
        "    def score(self, x):\n",
        "      return torch.sqrt((x ** 2).sum(dim=2))\n",
        "    \n",
        "    def forward(self, x):\n",
        "      x = self.conv_layers(x)\n",
        "      x = x.unsqueeze(2)\n",
        "      x = self.conv_capsule_layers(x)\n",
        "      x = x.transpose(1, 2)\n",
        "      x = self.capsule_average_pooling(x)\n",
        "      scores = self.score(x)\n",
        "      x = x.view(x.size(0), x.size(1) * x.size(2))\n",
        "      reconstructions = self.reconstruction_layer(x)\n",
        "      return scores, reconstructions"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qtTivCTQ1Uuo",
        "colab": {}
      },
      "source": [
        "model = CapsNet(num_classes=num_classes)\n",
        "model = model.to(dev)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_UKk0X4RKyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch,labels = next(iter(train_loader))\n",
        "batch = batch.to(dev)\n",
        "labels = labels.to(dev)\n",
        "scores, reconstructions = model(batch)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyMuXrGCEtHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, dev, lr=0.001):\n",
        "    try:\n",
        "        # Create model\n",
        "        model = CapsNet(num_classes=num_classes)\n",
        "        model = model.to(dev)\n",
        "        # Optimizer\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "        # Initialize history\n",
        "        history_loss = {\"train\": [], \"val\": [], \"test\": []}\n",
        "        history_accuracy = {\"train\": [], \"val\": [], \"test\": []}\n",
        "        # Process each epoch\n",
        "        for epoch in range(epochs):\n",
        "            # Initialize epoch variables\n",
        "            sum_loss = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "            sum_accuracy = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "            # Process each split\n",
        "            for split in [\"train\", \"val\", \"test\"]:\n",
        "                if split == \"train\":\n",
        "                  model.train()\n",
        "                else:\n",
        "                  model.eval()\n",
        "                # Process each batch\n",
        "                for (input, labels) in loaders[split]:\n",
        "                    # Move to CUDA\n",
        "                    input = input.to(dev)\n",
        "                    labels = labels.to(dev)\n",
        "                    # Reset gradients\n",
        "                    optimizer.zero_grad()\n",
        "                    # Compute output\n",
        "                    pred, reconstructions = model(input)\n",
        "                    print(pred)\n",
        "                    score_loss = F.cross_entropy(pred, labels)\n",
        "                    reconstruction_loss = F.mse_loss(input, reconstructions)\n",
        "                    loss = score_loss + reconstruction_loss\n",
        "                    # Update loss\n",
        "                    sum_loss[split] += loss.item()\n",
        "                    # Check parameter update\n",
        "                    if split == \"train\":\n",
        "                        # Compute gradients\n",
        "                        loss.backward()\n",
        "                        # Optimize\n",
        "                        optimizer.step()\n",
        "                    # Compute accuracy\n",
        "                    _,pred_labels = pred.max(1)\n",
        "                    batch_accuracy = (pred_labels == labels).sum().item()/input.size(0)\n",
        "                    # Update accuracy\n",
        "                    sum_accuracy[split] += batch_accuracy\n",
        "            # Compute epoch loss/accuracy\n",
        "            epoch_loss = {split: sum_loss[split]/len(loaders[split]) for split in [\"train\", \"val\", \"test\"]}\n",
        "            epoch_accuracy = {split: sum_accuracy[split]/len(loaders[split]) for split in [\"train\", \"val\", \"test\"]}\n",
        "            # Update history\n",
        "            for split in [\"train\", \"val\", \"test\"]:\n",
        "                history_loss[split].append(epoch_loss[split])\n",
        "                history_accuracy[split].append(epoch_accuracy[split])\n",
        "            # Print info\n",
        "            print(f\"Epoch {epoch+1}:\",\n",
        "                  f\"TrL={epoch_loss['train']:.4f},\",\n",
        "                  f\"TrA={epoch_accuracy['train']:.4f},\",\n",
        "                  f\"VL={epoch_loss['val']:.4f},\",\n",
        "                  f\"VA={epoch_accuracy['val']:.4f},\",\n",
        "                  f\"TeL={epoch_loss['test']:.4f},\",\n",
        "                  f\"TeA={epoch_accuracy['test']:.4f},\"\n",
        "                )\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Interrupted\")\n",
        "    finally:\n",
        "        # Plot loss\n",
        "        plt.title(\"Loss\")\n",
        "        for split in [\"train\", \"val\", \"test\"]:\n",
        "            plt.plot(history_loss[split], label=split)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        # Plot accuracy\n",
        "        plt.title(\"Accuracy\")\n",
        "        for split in [\"train\", \"val\", \"test\"]:\n",
        "            plt.plot(history_accuracy[split], label=split)\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggkhqnbdcMiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(100, dev)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}